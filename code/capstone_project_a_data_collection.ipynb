{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Books recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is always a need for book recommendation when one would like to start picking a new book to read. With the vast availability of book choices we have currently, readers are always faced with the situation to decide which books to select next and on average, the process of selecting a suitable book for the reader may take up a huge amount of time, effort and energy. With the rising trend of online platform preference, as a data scientist in the online bookstore, we aim to build a book recommendation system in our online bookstore website to help readers save up time to search for the books that they are interested in and match the books to their preference. Our team will explore the use of non-personalized recommendation system (popularity-based and content-based recommender system) and personalized recommendation system (collaborative filtering and model-based recommender systems) for predicting books ratings that the readers may rate. For personalized recommendation system, the recommender system's success will be evaluated based on the root mean square error (RMSE) between the actual and the predicted rating. This prediction will allow our bookstore website to recommend books that are more personalized to the readers, leading to an enhanced reader's experience and higher subscription rate, which may lead to an increase in business profitability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Contents:\n",
    "- [Background](#1.-Background) **(In this notebook)**\n",
    "- [Data Collection](#2.-Data-Collection) **(In this notebook)**\n",
    "- Data Cleaning Booklist\n",
    "- Data Cleaning Book Interactions\n",
    "- Exploratory Data Analysis\n",
    "* Non-personalized recommendation\n",
    "    - Modeling 1 Popularity-based and Content-based recommendation system \n",
    "* Personalized recommendation\n",
    "    - Modeling 2 Collaborative-filtering-based recommendation system\n",
    "    - Modeling 3 Clustering-Collaborative-filtering-based recommendation system\n",
    "    - Modeling 4 Model-based recommendation systems\n",
    "- Evaluation\n",
    "- Conclusion and Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading is a superfood for our brains and many of us read books throughout our journey of life. With the vast amount of books available (estimated 130 million books in 2010), readers often faced with the situation to decide which books to read next [[1]](https://mashable.com/2010/08/05/number-of-books-in-the-world/). As it is estimated that a person read about 12-120 books per year with some exceptional readers reading 200-300 books per year, they will be able to finish with a maximum of about 1 - 23 thousand books in their lifetime (with an estimated lifespan of a person having 80 years and subtracting the first 5 years of age) [[2]](https://lostinbook.com/how-many-books-should-i-read-a-year/)[[3]](https://bookriot.com/what-i-learned-from-reading-300-books-in-2017/). With the current available books and the rate of new books published about 2.2 million a year, a reader will not be able to read all the books available and would want to select the books that matches their choice of preference [[4]](https://ebookfriendly.com/countries-publish-most-books-infographic/). As a result, a book recommendation system becomes essential and very useful for readers who are undecided on which books to pick up next.\n",
    "\n",
    "On average, the process of selecting a suitable book for the reader may take up a huge amount of time, effort and energy. This process of selection may include through social media, online browsing or book referrals from friends. [[5]](https://www.nlb.gov.sg/Portals/0/Docs/AboutUs/2018%20NATIONAL%20READING%20HABITS%20STUDY%20ON%20ADULTS%20-%20REPORT.pdf). As a data scientist in the online bookstore, we aim to design and create a book recommender system in our online bookstore website to help readers save up time to search for the books that they are interested in and match to their preference. Our team will explore the use of non-personalized recommendation system (popularity-based and content-based recommender system) and personalized recommendation system (collaborative filtering and model-based recommender systems) for predicting the books that the readers would rate. For personalized recommendation system, the model's success will be evaluated based on the root mean square error (RMSE) between the actual and the predicted rating. This prediction will allow our online bookstore website to recommend books that are more personalized and customized to the readers' preference, provide a better and seamless reading experience for readers, which will lead to a higher sastisfaction and overall help to improve business and sales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Datasets\n",
    "\n",
    "As goodreads has one of the world's largest site for readers and book recommendations, we will be using the goodreads datasets obtained from [University of California San Diego Book Graph](https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home?authuser=0) to aid in the development of book recommendation system [6]. \n",
    "The assumption is goodread readers are random and come from all around the world, in which the data is symbolic of book buyers on online platform.\n",
    "The dataset contains meta-data of books and user-book interactions.\n",
    "\n",
    "The datasets obtained are as followed:-\n",
    "\n",
    "Meta-data of books:-\n",
    "* goodreads_books\n",
    "* goodreads_book_works\n",
    "* goodreads_book_authors\n",
    "* goodreads_book_series\n",
    "* goodreads_book_genres_initial\n",
    "\n",
    "User-book interactions:-\n",
    "* goodreads_interactions\n",
    "* book_id_map\n",
    "\n",
    "For more details, please refer to the data_dictionary.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "Goodreads_books.json.gz file is stored in a gzip file format and has a size of 2GB. The file could not be load directly and therefore the file is extracted in batches and saved in subfiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Define function for data collection from json.gz (large files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# book_total_line = sum(1 for line in gzip.open('./datasets/goodreads_books.json.gz'))\n",
    "# print(f\"Total line in goodreads book json is : {book_total_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((book_total_line/5)%5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collection_json(filepath, min_count, max_count):\n",
    "    count = 0\n",
    "    datalist = []\n",
    "    \n",
    "    with gzip.open(filepath) as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            count +=1\n",
    "            \n",
    "            if (count>min_count) & (count<=(max_count)):\n",
    "                datalist.append(data)\n",
    "                clear_output(wait=True)\n",
    "                print(f'progress: {count}/{max_count}')\n",
    "\n",
    "            elif count>(max_count):\n",
    "                break\n",
    "        \n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Collection from goodreads_books.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#booklist_first = data_collection_json('./datasets/goodreads_books.json.gz', 0, (book_total_line/5))\n",
    "#booklist_second = data_collection_json('./datasets/goodreads_books.json.gz', (book_total_line/5), ((book_total_line/5)*2))\n",
    "#booklist_third = data_collection_json('./datasets/goodreads_books.json.gz', ((book_total_line/5)*2), ((book_total_line/5)*3))\n",
    "#booklist_fourth = data_collection_json('./datasets/goodreads_books.json.gz', ((book_total_line/5)*3), ((book_total_line/5)*4))\n",
    "#booklist_fifth = data_collection_json('./datasets/goodreads_books.json.gz', ((book_total_line/5)*4), (((book_total_line/5)*5)+100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#booklist_first = pd.DataFrame(booklist_first)\n",
    "#booklist_second = pd.DataFrame(booklist_second)\n",
    "#booklist_third = pd.DataFrame(booklist_third)\n",
    "#booklist_fourth = pd.DataFrame(booklist_fourth)\n",
    "#booklist_fifth = pd.DataFrame(booklist_fifth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data exportation into other formats\n",
    "\n",
    "Parquet file format is a format that allows to process large data with small file size. For ease of data analysis of different datasets, the file will be changed into parquet file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "booklist_authors = pd.read_json(\"./datasets/goodreads_book_authors.json.gz\", lines = True)\n",
    "booklist_series = pd.read_json(\"./datasets/goodreads_book_series.json.gz\", lines = True)\n",
    "booklist_works = pd.read_json(\"./datasets/goodreads_book_works.json.gz\", lines = True)\n",
    "booklist_genres = pd.read_json(\"./datasets/goodreads_book_genres_initial.json.gz\", lines = True)\n",
    "booklist_interactions = pd.read_csv(\"./datasets/goodreads_interactions.csv\")\n",
    "book_id_map = pd.read_csv(\"./datasets/book_id_map.csv\")\n",
    "user_id_map = pd.read_csv(\"./datasets/user_id_map.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The goodreads_books.json has successfully collected and separated into five subfiles. These files will be exported as a parquet files.\n",
    "* The other documents have been imported and will be exported as a parquet file to be cleaned in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From goodreads_books.json.gz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placed the # to refrain from executing\n",
    "# booklist_first.to_csv(\"./data/booklist_first.csv\", index = False) \n",
    "# booklist_second.to_csv(\"./data/booklist_second.csv\", index = False) \n",
    "# booklist_third.to_csv(\"./data/booklist_third.csv\", index = False) \n",
    "# booklist_fourth.to_csv(\"./data/booklist_fourth.csv\", index = False) \n",
    "#booklist_fifth.to_csv(\"./data/booklist_fifth.csv\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#booklist_first.to_parquet('./data/booklist_first.parquet', compression='gzip')\n",
    "#booklist_second.to_parquet('./data/booklist_second.parquet', compression='gzip')\n",
    "#booklist_third.to_parquet('./data/booklist_third.parquet', compression='gzip')\n",
    "#booklist_fourth.to_parquet('./data/booklist_fourth.parquet', compression='gzip')\n",
    "#booklist_fifth.to_parquet('./data/booklist_fifth.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From goodreads_books.json.gz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "booklist_authors.to_parquet('./data/booklist_authors.parquet', compression='gzip')\n",
    "booklist_series.to_parquet('./data/booklist_series.parquet', compression='gzip')\n",
    "booklist_works.to_parquet('./data/booklist_works.parquet', compression='gzip')\n",
    "booklist_genres.to_parquet('./data/booklist_genres.parquet', compression='gzip')\n",
    "booklist_interactions.to_parquet('./data/booklist_interactions.parquet', compression='gzip')\n",
    "book_id_map.to_parquet('./data/book_id_map.parquet', compression='gzip')\n",
    "user_id_map.to_parquet('./data/user_id_map.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] B. Parr, \"Google: There are 129,864,880 Books in the Entire World,\" *Mashable, Inc.*, August 06, 2010. [Online]. Available:https://mashable.com/2010/08/05/number-of-books-in-the-world/ [Accessed: June 06, 2021].\n",
    "\n",
    "[2] E. Yilmaz, \"How Many Books Should I Read in a Year?,\" *Lost In Book*, August 05, 2020. [Online]. Available:https://lostinbook.com/how-many-books-should-i-read-a-year/ [Accessed: June 06, 2021].\n",
    "\n",
    "[3] L. Sackton, \"What I learned from reading 300+ books in 2017,\" *Book Riot*, January 08, 2018 [Online]. Available:https://bookriot.com/what-i-learned-from-reading-300-books-in-2017/ [Accessed: June 06, 2021].\n",
    "\n",
    "[4] P. Kowalczyk, \"Which countries publish the most books? (Infographic),\" *Ebook Friendly*, April 06, 2017 [Online]. Available:https://ebookfriendly.com/countries-publish-most-books-infographic/ [Accessed: June 06, 2021].\n",
    "\n",
    "[5] \"2018 National Reading Habits Study on Adults,\" *National Library Board Singapore*, 2019. [Online]. Available:https://www.nlb.gov.sg/Portals/0/Docs/AboutUs/2018%20NATIONAL%20READING%20HABITS%20STUDY%20ON%20ADULTS%20-%20REPORT.pdf [Accessed: May 10, 2021].\n",
    "\n",
    "[6] M. Wan, and J. McAuley, \"Item Recommendation on Monotonic Behavior Chains,\" *Proceedings of the 12th ACM conference on Recommender Systems, RecSys 2018*, September 2018, pp. 86-94. doi: 10.1145/3240323.3240369 [Online]. Available:https://dl.acm.org/doi/10.1145/3240323.3240369 [Accessed: May 10, 2021]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
